{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QUR_8TxjwT6c"
   },
   "outputs": [],
   "source": [
    "import Graph_Amazon_Movies as gam\n",
    "import Amazon_Movie_Parser as amp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from networkx.algorithms import bipartite\n",
    "import networkx as nx\n",
    "import Amazon_Movie_Parser as prs\n",
    "import datetime\n",
    "from numpy import savetxt\n",
    "import Computations_debug as comp\n",
    "import random\n",
    "\n",
    "import Predict_Movie as pm\n",
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_amazon = pm.Amazon()\n",
    "#predict_amazon.debug_mode = 'On'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_movies = 20000 .. n_movies_v = 20000 .. n_test_users = 100\n",
      "walk_steps = 40 .. top_neighbor = 50\n",
      "----------------------------------------------\n",
      "Calculation starts for above values: 2020-05-15 10:40:21.937578\n",
      "*************** 1st Graph calculations - MODEL *************** \n",
      "Calculation time-Crete graph from the movies file: 0:00:07.693573\n",
      "Is connected: True ... Is bipartite: True\n",
      "BEFORE: # of nodes: 15859 ... # of edges: 19008\n",
      "Calculation time-1st Part: 0:00:08.373914\n",
      "\n",
      "*************** 2nd Graph calculations - TEST *************** \n",
      "Create_Bipartite_VALIDATION is running...\n",
      "Calculation time-Crete graph from the movies file: 0:00:08.086595\n",
      "Is connected: True ... Is bipartite: True\n",
      "BEFORE: # of nodes: 15651 ... # of edges: 18687\n",
      "n_reviews for modeling (P matrix) = 338 .. n_movies for testing = 384\n",
      "n_users for modeling (P matrix) = 15521 .. n_users for testing = 15267\n",
      "Calculation time-2nd Part: 0:00:08.793105\n",
      "**********************************************\n",
      "Calculation time for ALL-Part-1: 0:00:17.168671\n",
      "Preparation starts at 2020-05-15 10:40:39.106437\n",
      "P to_numpy_matrix: 2020-05-15 10:40:39.768863\n",
      "P normalize: 2020-05-15 10:40:41.396405\n",
      "P finalize: 2020-05-15 10:40:42.371783\n",
      "Calculation time-P matrix generation from the graph: 0:00:02.602920\n",
      "Calculation time-user-movie indexes: 0:00:03.062545\n",
      "\n",
      "\n",
      "Calculation time-user-movie indexes: 0:00:03.262146\n",
      "\n",
      "\n",
      "0. of 100 Random walk starts for 859-AJMU8VVFKMZI4 at 2020-05-15 10:41:02.055773\n",
      "10. of 100 Random walk starts for 1885-A3KXV8AFQ550DY at 2020-05-15 10:43:17.039901\n",
      "20. of 100 Random walk starts for 6177-A2OTZMERC41JDB at 2020-05-15 10:45:29.487540\n",
      "30. of 100 Random walk starts for 3324-A96ROTPFCSWTR at 2020-05-15 10:47:41.770302\n",
      "40. of 100 Random walk starts for 2125-ATRYT5ZKNLN9C at 2020-05-15 10:49:52.654566\n",
      "50. of 100 Random walk starts for 14819-A28MM46KI4EQB2 at 2020-05-15 10:52:05.326522\n",
      "60. of 100 Random walk starts for 4467-AK61LQI92GTCH at 2020-05-15 10:54:17.287609\n",
      "70. of 100 Random walk starts for 13052-A2M8AHUJSRCPXH at 2020-05-15 10:56:29.702741\n",
      "80. of 100 Random walk starts for 13471-AS18HUSD425L3 at 2020-05-15 10:58:40.811649\n",
      "90. of 100 Random walk starts for 8039-A2HII4U9WQ0XUV at 2020-05-15 11:00:52.150130\n",
      "99. of 100 Random walk starts for 4105-A1WGF3DAX2WUV0 at 2020-05-15 11:02:51.831560\n",
      "MOVIES >> YES: Exist in both .. NO: Exist in dataset-2 but not exist in dataset-1\n",
      "count_YES: 1 .. count_NO: 383\n",
      "USERS >> YES: Exist in both .. NO: Exist in dataset-2 but not exist in dataset-1\n",
      "count_YES: 1939 .. count_NO: 13328\n",
      "MOVIES >> YES: Exist in both .. NO: Exist in dataset-1 but not exist in dataset-2\n",
      "count_YES: 1 .. count_NO: 337\n",
      "USERS >> YES: Exist in both .. NO: Exist in dataset-1 but not exist in dataset-2\n",
      "count_YES: 1939 .. count_NO: 13582\n",
      "**********************************************\n",
      "Calculation time for ALL-Predictions: 0:22:13.734951\n",
      "Performance Values are saved in RESULTS/PerformanceValues_0.7459_15.5.2020_11.3.30.csv\n",
      "Prediction Details are saved in RESULTS/PredictionDetails_20000_20000_100_40_50_15.5.2020_11.3.30.csv\n",
      "\n",
      "n_movies = 30000 .. n_movies_v = 20000 .. n_test_users = 100\n",
      "walk_steps = 40 .. top_neighbor = 50\n",
      "----------------------------------------------\n",
      "Calculation starts for above values: 2020-05-15 11:03:30.562294\n",
      "*************** 1st Graph calculations - MODEL *************** \n",
      "Calculation time-Crete graph from the movies file: 0:00:19.488269\n",
      "Is connected: True ... Is bipartite: True\n",
      "BEFORE: # of nodes: 23385 ... # of edges: 28701\n",
      "Calculation time-1st Part: 0:00:20.568518\n",
      "\n",
      "*************** 2nd Graph calculations - TEST *************** \n",
      "Create_Bipartite_VALIDATION is running...\n",
      "Calculation time-Crete graph from the movies file: 0:00:08.063108\n",
      "Is connected: True ... Is bipartite: True\n",
      "BEFORE: # of nodes: 15651 ... # of edges: 18687\n",
      "n_reviews for modeling (P matrix) = 549 .. n_movies for testing = 384\n",
      "n_users for modeling (P matrix) = 22836 .. n_users for testing = 15267\n",
      "Calculation time-2nd Part: 0:00:08.770904\n",
      "**********************************************\n",
      "Calculation time for ALL-Part-1: 0:00:29.356231\n",
      "Preparation starts at 2020-05-15 11:03:59.918711\n",
      "P to_numpy_matrix: 2020-05-15 11:04:00.659442\n",
      "P normalize: 2020-05-15 11:04:03.659166\n",
      "P finalize: 2020-05-15 11:04:05.810498\n",
      "Calculation time-P matrix generation from the graph: 0:00:05.151054\n",
      "Calculation time-user-movie indexes: 0:00:06.773225\n",
      "\n",
      "\n",
      "Calculation time-user-movie indexes: 0:00:02.613488\n",
      "\n",
      "\n",
      "0. of 100 Random walk starts for 16887-AY0QXNZ5IHIIO at 2020-05-15 11:04:35.894389\n",
      "10. of 100 Random walk starts for 21075-AF5K86Z6REUTE at 2020-05-15 11:08:12.659318\n"
     ]
    }
   ],
   "source": [
    "file_name = 'data/movies.txt'; n_movies = 20000; n_movies_v = 20000; n_test_users = 100; walk_steps = 40\n",
    "start_index_v = n_movies; beta = 0.15; top_neighbor = 50\n",
    "\n",
    "#file_name = 'data/movies.txt'; n_movies = 2000; n_movies_v = 2000; n_test_users = 40; walk_steps = 30\n",
    "#start_index_v = n_movies; beta = 0.15; top_neighbor = 50\n",
    "\n",
    "lst_n_movies_test = [20000, 30000, 40000, 50000]\n",
    "#lst_n_movies_test = [2000, 3000, 4000, 5000]\n",
    "#lst_n_movies_test_v = [10000, 15000, 20000, 30000]\n",
    "\n",
    "start_time_ALL = datetime.datetime.now()\n",
    "for n_movies in lst_n_movies_test:\n",
    "    start_time_part1 = datetime.datetime.now()\n",
    "\n",
    "    print('\\nn_movies = {} .. n_movies_v = {} .. n_test_users = {}'.format(n_movies, n_movies_v, n_test_users))\n",
    "    print('walk_steps = {} .. top_neighbor = {}'.format(walk_steps, top_neighbor))\n",
    "    print('----------------------------------------------')\n",
    "    print('Calculation starts for above values: {}'.format(start_time_part1))\n",
    "\n",
    "    max_connected_gr_amazon_movies, max_connected_gr_amazon_movies_VAL = \\\n",
    "    predict_amazon.create_graphs(file_name, n_movies, n_movies_v, start_index_v)\n",
    "\n",
    "    end_time_part1 = datetime.datetime.now()\n",
    "    total_time_part1 = end_time_part1 - start_time_part1\n",
    "    print('**********************************************')\n",
    "    print('Calculation time for ALL-Part-1: {}'.format(total_time_part1))\n",
    "    \n",
    "    start_time_part2 = datetime.datetime.now()\n",
    "\n",
    "    df_FINAL = \\\n",
    "    predict_amazon.run_validation(max_connected_gr_amazon_movies, max_connected_gr_amazon_movies_VAL,\\\n",
    "                                  walk_steps, n_test_users, beta, top_neighbor)\n",
    "\n",
    "    end_time_part2 = datetime.datetime.now()\n",
    "    total_time_part2 = end_time_part2 - start_time_part1\n",
    "    \n",
    "    # df_perf is saved in a csv, too, but it i done in the function \"save_performance_values\"\n",
    "    df_perf = predict_amazon.save_performance_values(df_FINAL, total_time_part1, total_time_part2)\n",
    "\n",
    "    file_prefix = \"RESULTS/PredictionDetails_\" + str(n_movies) + \"_\" + str(n_movies_v) + \"_\" + \\\n",
    "    str(n_test_users) + \"_\" + str(walk_steps) + \"_\" + str(top_neighbor) + \"_\"\n",
    "                                                \n",
    "    #fileName_Details = prs.FileNameUnique(prefix = \"RESULTS/PredictionDetails_\", suffix = '.csv')\n",
    "    fileName_Details = prs.FileNameUnique(prefix = file_prefix, suffix = '.csv')\n",
    "    df_FINAL.to_csv(fileName_Details)\n",
    "    print('Prediction Details are saved in {}'.format(fileName_Details))\n",
    "    df_perf\n",
    "\n",
    "end_time_ALL = datetime.datetime.now()\n",
    "print('Calculation time for ALL-Predictions: {}'.format(end_time_ALL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_df = predict_amazon.show_parameters_in_use()\n",
    "params_df.style.set_properties(**{'text-align': 'left'})\n",
    "\n",
    "df_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lst_length=12\n",
    "lst_other_metrics_name = list(np.zeros(max_lst_length, str))\n",
    "lst_other_metrics_value = list(np.zeros(max_lst_length, str))\n",
    "\n",
    "lst_other_metrics_name_prep = ['threshold',  'acc', 'tpr', 'fpr', 'tnr', 'ppv', 'f1']\n",
    "lst_other_metrics_value_prep = [1,  2, 3, 4, 5, 6, 7]\n",
    "        \n",
    "for i, val in enumerate(lst_other_metrics_name_prep):\n",
    "    lst_other_metrics_name[i] = val\n",
    "for i, val in enumerate(lst_other_metrics_value_prep):\n",
    "    lst_other_metrics_value[i] = val\n",
    "    \n",
    "print(lst_other_metrics_name)\n",
    "print(lst_other_metrics_value)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Amazon_movies.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
