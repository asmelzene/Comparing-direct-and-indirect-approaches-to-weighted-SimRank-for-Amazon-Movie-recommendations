{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QUR_8TxjwT6c"
   },
   "outputs": [],
   "source": [
    "import Amazon_Movie_Parser as prs\n",
    "import Graph_Amazon_Movies_2 as gam\n",
    "#import Computations_debug_2 as comp\n",
    "import Computations_debug_3 as comp\n",
    "#import Predict_Movie_v2 as pm\n",
    "import Predict_Movie_v3 as pm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "import datetime\n",
    "#from numpy import savetxt\n",
    "#import random\n",
    "\n",
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you run this in colab *** it has a very limited RAM 12GB if I'm not mistaken, so works for 20K not 40K\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_amazon = pm.Amazon()\n",
    "#predict_amazon.debug_mode = 'On'\n",
    "#predict_amazon.file_type = 'pickle'\n",
    "# **** we need to filter out the movies the person has already reviewed previously ****\n",
    "# because the same movie can appear in the test data-set since some new users might review it this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_movies = 5625 .. n_movies_v = 1400 .. n_test_users = 65\n",
      "walk_steps = 40 .. top_neighbor = 20\n",
      "----------------------------------------------\n",
      "Calculation starts for above values: 2020-06-01 12:24:20.406202\n",
      "*************** 1st Graph calculations - MODEL *************** \n",
      "num_limit=500000, num_reviews=7025, date_year=2009\n",
      "max_date: 2009-12-31 min_date: 2009-01-01\n",
      "2009: 7025 .. 2010: 0 .. 2011: 0 .. 2012: 0\n",
      "Calculation time-Crete graph from the movies file: 0:00:01.987069\n",
      "Is connected: True ... Is bipartite: True\n",
      "# of nodes: 3309 ... # of edges: 3918\n",
      "Calculation time-1st Part: 0:00:02.103864\n",
      "\n",
      "*************** 2nd Graph calculations - TEST *************** \n",
      "Is connected: True ... Is bipartite: True\n",
      "# of nodes: 657 ... # of edges: 832\n",
      "n_movies for modeling (P matrix) = 357 .. n_movies for testing = 69\n",
      "n_users for modeling (P matrix) = 2952 .. n_users for testing = 588\n",
      "Avg degree (edge) per user in MODELING GRAPH: 1.3272357723577235  ... in TEST GRAPH: 1.4149659863945578\n",
      "Calculation time-2nd Part: 0:00:00.053112\n",
      "**********************************************\n",
      "Calculation time for ALL-Part-1: 0:00:02.158263\n",
      "Preparation starts at 2020-06-01 12:24:22.564596\n",
      "P to_numpy_matrix: 2020-06-01 12:24:22.636992\n",
      "P normalize: 2020-06-01 12:24:22.721860\n",
      "P finalize: 2020-06-01 12:24:22.768418\n",
      "Calculation time-P matrix generation from the graph: 0:00:00.131426\n",
      "P_norm is generated: 2020-06-01 12:24:22.774398\n",
      "Calculation time-user-movie indexes: 0:00:00.122092\n",
      "\n",
      "\n",
      "Calculation time-user-movie indexes: 0:00:00.003595\n",
      "\n",
      "\n",
      "FOR loop starts for TEST users (ref users): 2020-06-01 12:24:22.907802\n",
      "0. of 65 Random walk starts for 1529-A2NKPGY3A4A911 at 2020-06-01 12:24:22.908625\n",
      "Calculate the ratios per movie: 0\n",
      "mv_new=B00004WCMT: 35.0\n",
      "mv_new=B0083SI986: 15.0\n",
      "mv_new=B006RXQ6FM: 65.0\n",
      "mv_new=B000EQ5V8G: 25.0\n",
      "mv_new=B006RXQ6FM: 30.0\n",
      "mv_new=B0019RP6KC: 60.0\n",
      "mv_new=B000Z8GZYW: 10.0\n",
      "mv_new=B001LMU1A0: 70.0\n",
      "mv_new=B0083SI986: 10.0\n",
      "mv_new=B0083SI986: 50.0\n",
      "10. of 65 Random walk starts for 2959-A34GZPHWYPSY2T at 2020-06-01 12:24:53.615089\n",
      "Calculate the ratios per movie: 10\n",
      "mv_new=B0083SI986: 45.0\n",
      "mv_new=B006RXQ6FM: 20.0\n",
      "mv_new=B00112S8RS: 65.0\n",
      "mv_new=B000KKQNRO: 15.0\n",
      "mv_new=B006RXQ6FM: 30.0\n",
      "mv_new=6301967917: 5.0\n",
      "mv_new=B001ILFUDM: 10.0\n",
      "mv_new=B001JI7WTO: 20.0\n",
      "mv_new=B0083SI986: 45.0\n",
      "mv_new=B006RXQ6FM: 35.0\n",
      "20. of 65 Random walk starts for 2657-A2Q5Y2EMS6KDWI at 2020-06-01 12:25:25.171698\n",
      "Calculate the ratios per movie: 20\n",
      "mv_new=B0016MOV92: 45.0\n",
      "mv_new=B001OKUREO: 10.0\n",
      "mv_new=B002SEQ8ZW: 25.0\n",
      "mv_new=B0083SI986: 45.0\n",
      "mv_new=B00005Y6Y2: 15.0\n",
      "mv_new=B0083SI986: 15.0\n",
      "mv_new=B001ILFUDM: 15.0\n",
      "mv_new=B001FB55HQ: 10.0\n",
      "mv_new=B006RXQ6FM: 20.0\n",
      "mv_new=B002SEQ8ZM: 25.0\n",
      "30. of 65 Random walk starts for 1656-A3KO1QOAMYHWY4 at 2020-06-01 12:25:57.001734\n",
      "Calculate the ratios per movie: 30\n",
      "mv_new=B002O3Z4W0: 55.00000000000001\n",
      "mv_new=B0083SI986: 15.0\n",
      "mv_new=B0083SI986: 20.0\n",
      "mv_new=B001OKUREO: 25.0\n",
      "mv_new=630243940X: 5.0\n",
      "mv_new=B001E6JCBC: 30.0\n",
      "mv_new=B0006IWQIU: 35.0\n",
      "mv_new=B000068TWC: 5.0\n",
      "mv_new=B002OHDRF2: 10.0\n",
      "mv_new=B002YJMMBA: 20.0\n",
      "40. of 65 Random walk starts for 1942-A9RNMO9MUSMTJ at 2020-06-01 12:26:27.936857\n",
      "Calculate the ratios per movie: 40\n",
      "mv_new=B006RXQ6FM: 30.0\n",
      "mv_new=B00005V9IK: 30.0\n",
      "mv_new=B0083SI986: 45.0\n",
      "mv_new=B00004UF19: 15.0\n",
      "mv_new=0767805534: 10.0\n",
      "mv_new=B001OKUREO: 30.0\n",
      "mv_new=B001JI7WTO: 15.0\n",
      "mv_new=B006RXQ6FM: 45.0\n",
      "mv_new=B00015HX9A: 35.0\n",
      "mv_new=076780046X: 35.0\n",
      "50. of 65 Random walk starts for 1246-AQP1VPK16SVWM at 2020-06-01 12:26:58.038238\n",
      "Calculate the ratios per movie: 50\n",
      "mv_new=B0083SI986: 45.0\n",
      "mv_new=B006RXQ6FM: 15.0\n",
      "mv_new=B0083SI986: 45.0\n",
      "mv_new=076780046X: 30.0\n",
      "mv_new=B0000CDUXK: 20.0\n",
      "mv_new=B00004RF5S: 5.0\n",
      "mv_new=B001ILFUDM: 20.0\n",
      "mv_new=B006RXQ6FM: 30.0\n",
      "mv_new=B0083SI986: 15.0\n",
      "mv_new=B008X1O7KM: 60.0\n",
      "60. of 65 Random walk starts for 139-A2IZIYYCEGOMEU at 2020-06-01 12:27:27.965878\n",
      "Calculate the ratios per movie: 60\n",
      "mv_new=B00112S8RS: 10.0\n",
      "mv_new=B00008WJDH: 5.0\n",
      "mv_new=B009HNDF3K: 10.0\n",
      "mv_new=B002YJMMBA: 10.0\n",
      "64. of 65 Random walk starts for 413-A19ZXK9HHVRV1X at 2020-06-01 12:27:39.934163\n",
      "Calculate the ratios per movie: 64\n",
      "mv_new=B0083SI986: 10.0\n",
      "MOVIES >> YES: Exist in both .. NO: Exist in dataset-2 but not exist in dataset-1\n",
      "count_YES: 53 .. count_NO: 16\n",
      "USERS >> YES: Exist in both .. NO: Exist in dataset-2 but not exist in dataset-1\n",
      "count_YES: 72 .. count_NO: 516\n",
      "MOVIES >> YES: Exist in both .. NO: Exist in dataset-1 but not exist in dataset-2\n",
      "count_YES: 53 .. count_NO: 304\n",
      "USERS >> YES: Exist in both .. NO: Exist in dataset-1 but not exist in dataset-2\n",
      "count_YES: 72 .. count_NO: 2880\n",
      "**********************************************\n",
      "Calculation time for run_validation_TOP_N: 0:03:20.507314\n",
      "Performance Values are saved in RESULTS/PerformanceValues_0.5288_1.6.2020_12.27.43.csv\n",
      "fpr, tpr, thresholds  starts: 2020-06-01 12:27:43.521432\n",
      "roc_auc starts: 2020-06-01 12:27:43.524035\n",
      "lst_thresholds starts: 2020-06-01 12:27:43.526436\n",
      "lst_presicion_based starts: 2020-06-01 12:27:43.526479\n",
      "lst_other_metrics_name_prep starts: 2020-06-01 12:27:43.526501\n",
      "Performance Values are saved in RESULTS/PerformanceValues_ALL_0.6942_1.6.2020_12.27.43.csv\n",
      "Prediction Details are saved in RESULTS/PredictionDetails_5625_1400_65_40_20_TOP1_1.6.2020_12.27.43.csv\n",
      "Prediction_all Details are saved in RESULTS/PredictionDetails_ALL_5625_1400_65_40_20_TOP1_1.6.2020_12.27.43.csv\n",
      "Calculation time for ALL-Predictions: 2020-06-01 12:27:43.569646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n>>>> df_FINAL (PredictionDetails.csv file)\\n> prediction: our prediction whether or not the given user will review the given movie on the list or not \\ndepending on the given threshold\\n> reality: \\n> threshold: if ngbr_ratio > threshold then prediction=1 else 0\\n> ngbr_ratio: how many percent of your top-K similar users reviewed this movie\\n> tot_rev_m: how many times was this movie reviewed \\n> n_old_edge: how many times did this user make a review in the old dataset\\n> n_new_edge: how many times did this user make a review in the new dataset\\n'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'data/movies.txt'; n_movies = 5625; n_movies_v = 20500; n_test_users = 65; walk_steps = 40\n",
    "start_index_v = n_movies; beta = 0.15; top_neighbor = 20; top_N_movie_suggestions = 1\n",
    "num_limit=500000; date_year=2009\n",
    "\n",
    "#file_name = 'data/movies.txt'; n_movies = 2000; n_movies_v = 2000; n_test_users = 40; walk_steps = 30\n",
    "#start_index_v = n_movies; beta = 0.15; top_neighbor = 50\n",
    "\n",
    "#lst_n_movies_test = [20000, 30000, 40000, 50000]\n",
    "#lst_n_movies_test_v = [10000, 13000, 15000, 18000, 20000]\n",
    "#lst_n_movies_test_v = [3000, 5000, 9000, 14000]\n",
    "#lst_n_movies_test_v = [2000, 4000, 6000, 8000]\n",
    "lst_n_movies_test_v = [1400]  # 4038-February\n",
    "\n",
    "start_time_ALL = datetime.datetime.now()\n",
    "#for n_movies in lst_n_movies_test:\n",
    "for n_movies_v in lst_n_movies_test_v:\n",
    "    start_index_v = n_movies\n",
    "    start_time_part1 = datetime.datetime.now()\n",
    "\n",
    "    print('\\nn_movies = {} .. n_movies_v = {} .. n_test_users = {}'.format(n_movies, n_movies_v, n_test_users))\n",
    "    print('walk_steps = {} .. top_neighbor = {}'.format(walk_steps, top_neighbor))\n",
    "    print('----------------------------------------------')\n",
    "    print('Calculation starts for above values: {}'.format(start_time_part1))\n",
    "\n",
    "    max_connected_gr_amazon_movies, max_connected_gr_amazon_movies_VAL = \\\n",
    "    predict_amazon.create_graphs(file_name, n_movies, n_movies_v, start_index_v, num_limit, date_year)\n",
    "\n",
    "    end_time_part1 = datetime.datetime.now()\n",
    "    total_time_part1 = end_time_part1 - start_time_part1\n",
    "    print('**********************************************')\n",
    "    print('Calculation time for ALL-Part-1: {}'.format(total_time_part1))\n",
    "    \n",
    "    start_time_part2 = datetime.datetime.now()\n",
    "\n",
    "    '''\n",
    "    df_FINAL = \\\n",
    "    predict_amazon.run_validation(max_connected_gr_amazon_movies, max_connected_gr_amazon_movies_VAL,\\\n",
    "                                  walk_steps, n_test_users, beta, top_neighbor)\n",
    "    '''\n",
    "    '''\n",
    "    df_FINAL = \\\n",
    "    predict_amazon.run_validation_TOP_N(max_connected_gr_amazon_movies, max_connected_gr_amazon_movies_VAL,\\\n",
    "                                  walk_steps, n_test_users, beta, top_neighbor, top_N_movie_suggestions)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    df_FINAL, df_FINAL_all = \\\n",
    "    predict_amazon.run_validation_TOP_N(max_connected_gr_amazon_movies, max_connected_gr_amazon_movies_VAL,\\\n",
    "                                  walk_steps, n_test_users, beta, top_neighbor, top_N_movie_suggestions)\n",
    "\n",
    "    end_time_part2 = datetime.datetime.now()\n",
    "    total_time_part2 = end_time_part2 - start_time_part2\n",
    "    \n",
    "    #start_time_part3 = datetime.datetime.now()\n",
    "    # df_perf is saved in a csv, too, but it i done in the function \"save_performance_values\"\n",
    "    df_perf = predict_amazon.save_performance_values(df_FINAL, total_time_part1, total_time_part2)\n",
    "    \n",
    "    df_perf_all = predict_amazon.save_performance_values_ALL(df_FINAL_all, total_time_part1, total_time_part2)\n",
    "    #end_time_part3 = datetime.datetime.now()\n",
    "    #total_time_part3 = end_time_part3 - start_time_part3\n",
    "\n",
    "    # just to avoid failure if there is no RESULTS directory\n",
    "    try:\n",
    "        file_prefix = \"RESULTS/PredictionDetails_\" + str(n_movies) + \"_\" + str(n_movies_v) + \"_\" + \\\n",
    "        str(n_test_users) + \"_\" + str(walk_steps) + \"_\" + str(top_neighbor) + \\\n",
    "        \"_TOP\" + str(top_N_movie_suggestions) + \"_\"\n",
    "        \n",
    "        file_prefix_all = \"RESULTS/PredictionDetails_ALL_\" + str(n_movies) + \"_\" + str(n_movies_v) + \"_\" + \\\n",
    "        str(n_test_users) + \"_\" + str(walk_steps) + \"_\" + str(top_neighbor) + \\\n",
    "        \"_TOP\" + str(top_N_movie_suggestions) + \"_\"\n",
    "    except:\n",
    "        file_prefix = \"PredictionDetails_\" + str(n_movies) + \"_\" + str(n_movies_v) + \"_\" + \\\n",
    "        str(n_test_users) + \"_\" + str(walk_steps) + \"_\" + str(top_neighbor) + \\\n",
    "        \"_TOP\" + str(top_N_movie_suggestions) + \"_\"\n",
    "        \n",
    "        file_prefix_all = \"PredictionDetails_ALL_\" + str(n_movies) + \"_\" + str(n_movies_v) + \"_\" + \\\n",
    "        str(n_test_users) + \"_\" + str(walk_steps) + \"_\" + str(top_neighbor) + \\\n",
    "        \"_TOP\" + str(top_N_movie_suggestions) + \"_\"\n",
    "                                                \n",
    "    #fileName_Details = prs.FileNameUnique(prefix = \"RESULTS/PredictionDetails_\", suffix = '.csv')\n",
    "    fileName_Details = prs.FileNameUnique(prefix = file_prefix, suffix = '.csv')\n",
    "    fileName_Details_all = prs.FileNameUnique(prefix = file_prefix_all, suffix = '.csv')\n",
    "    \n",
    "    df_FINAL.to_csv(fileName_Details)\n",
    "    df_FINAL_all.to_csv(fileName_Details_all)\n",
    "    print('Prediction Details are saved in {}'.format(fileName_Details))\n",
    "    print('Prediction_all Details are saved in {}'.format(fileName_Details_all))\n",
    "    df_perf\n",
    "\n",
    "end_time_ALL = datetime.datetime.now()\n",
    "print('Calculation time for ALL-Predictions: {}'.format(end_time_ALL))\n",
    "os.system('say \"your program has finished\"')\n",
    "\n",
    "# it is taking SOOOOOO LONG time, had to stop it (even for 12K edges). Let's try in smaller networks later..\n",
    "#d_model = nx.diameter(max_connected_gr_amazon_movies)\n",
    "#d_test = nx.diameter(max_connected_gr_amazon_movies)\n",
    "\n",
    "#print('Diameter of MODEL: {}\\tTEST: {}'.format(d_model, d_test))\n",
    "\n",
    "'''\n",
    ">>>> df_FINAL (PredictionDetails.csv file)\n",
    "> prediction: our prediction whether or not the given user will review the given movie on the list or not \n",
    "depending on the given threshold\n",
    "> reality: \n",
    "> threshold: if ngbr_ratio > threshold then prediction=1 else 0\n",
    "> ngbr_ratio: how many percent of your top-K similar users reviewed this movie\n",
    "> tot_rev_m: how many times was this movie reviewed \n",
    "> n_old_edge: how many times did this user make a review in the old dataset\n",
    "> n_new_edge: how many times did this user make a review in the new dataset\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B0083SI986']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 1000\n",
    "predict_amazon.df_summary_ratio_v.sort_values(by='ratio_similar', ascending=False).head(1)['movie'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_new='B001NZWEI2'\n",
    "predict_amazon.df_summary_ratio_v.query(\"movie=='\" + mv_new + \"'\").values[0].tolist()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>TPR</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Thresholds</th>\n",
       "      <th>Calc_Time</th>\n",
       "      <th>lst_name</th>\n",
       "      <th>lst_value</th>\n",
       "      <th>other_metrics</th>\n",
       "      <th>metrics_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.52877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>Graph Creation</td>\n",
       "      <td>debug_mode</td>\n",
       "      <td>Off</td>\n",
       "      <td>threshold</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0178571</td>\n",
       "      <td>70</td>\n",
       "      <td>0:00:02.158263</td>\n",
       "      <td>n_movies_model</td>\n",
       "      <td>5625</td>\n",
       "      <td>acc</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0357143</td>\n",
       "      <td>65</td>\n",
       "      <td>Random Walk &amp; Prediction</td>\n",
       "      <td>n_movies_validation</td>\n",
       "      <td>1400</td>\n",
       "      <td>tpr</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0714286</td>\n",
       "      <td>60</td>\n",
       "      <td>0:03:20.514540</td>\n",
       "      <td>walk_steps</td>\n",
       "      <td>40</td>\n",
       "      <td>fpr</td>\n",
       "      <td>0.0357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>50</td>\n",
       "      <td>Threshold search</td>\n",
       "      <td>beta</td>\n",
       "      <td>0.15</td>\n",
       "      <td>tnr</td>\n",
       "      <td>0.964286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>45</td>\n",
       "      <td>0:00:00.363706</td>\n",
       "      <td>top_neighbor</td>\n",
       "      <td>20</td>\n",
       "      <td>fnr</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>35</td>\n",
       "      <td>TOTAL TIME</td>\n",
       "      <td>n_test_users</td>\n",
       "      <td>65</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>30</td>\n",
       "      <td>0:03:23.036509</td>\n",
       "      <td>threshold</td>\n",
       "      <td>60</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.5</td>\n",
       "      <td>25</td>\n",
       "      <td></td>\n",
       "      <td>start_index_v</td>\n",
       "      <td>5625</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>20</td>\n",
       "      <td></td>\n",
       "      <td>file_name</td>\n",
       "      <td>data/movies.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>top_N_suggestions</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>decision_4</td>\n",
       "      <td>0.080357</td>\n",
       "      <td>0.138462</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           AUC       TPR  Precision        FPR Thresholds  \\\n",
       "0   0.52877     0.000000  0.000000   0          71          \n",
       "1               0.000000  0.000000   0.0178571  70          \n",
       "2               0.111111  0.000000   0.0357143  65          \n",
       "3               0.111111  0.333333   0.0714286  60          \n",
       "4               0.111111  0.166667   0.107143   50          \n",
       "5               0.444444  0.142857   0.196429   45          \n",
       "6               0.444444  0.266667   0.285714   35          \n",
       "7               0.444444  0.200000   0.428571   30          \n",
       "8               0.444444  0.142857   0.5        25          \n",
       "9               0.555556  0.125000   0.607143   20          \n",
       "10              0.666667  0.128205   0.767857   15          \n",
       "11              1.000000  0.122449   0.910714   10          \n",
       "12              1.000000  0.150000   1          5           \n",
       "13  decision_4  0.080357  0.138462                          \n",
       "\n",
       "                   Calc_Time             lst_name        lst_value  \\\n",
       "0   Graph Creation            debug_mode           Off               \n",
       "1   0:00:02.158263            n_movies_model       5625              \n",
       "2   Random Walk & Prediction  n_movies_validation  1400              \n",
       "3   0:03:20.514540            walk_steps           40                \n",
       "4   Threshold search          beta                 0.15              \n",
       "5   0:00:00.363706            top_neighbor         20                \n",
       "6   TOTAL TIME                n_test_users         65                \n",
       "7   0:03:23.036509            threshold            60                \n",
       "8                             start_index_v        5625              \n",
       "9                             file_name            data/movies.txt   \n",
       "10                            top_N_suggestions    1                 \n",
       "11                                                                   \n",
       "12                                                                   \n",
       "13                                                                   \n",
       "\n",
       "   other_metrics metrics_val  \n",
       "0   threshold     60          \n",
       "1   acc           0.846154    \n",
       "2   tpr           0.111111    \n",
       "3   fpr           0.0357143   \n",
       "4   tnr           0.964286    \n",
       "5   fnr           0.888889    \n",
       "6   precision     0.333333    \n",
       "7   f1            0.166667    \n",
       "8                             \n",
       "9                             \n",
       "10                            \n",
       "11                            \n",
       "12                            \n",
       "13                            "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Calc_Time</th>\n",
       "      <th>lst_name</th>\n",
       "      <th>lst_value</th>\n",
       "      <th>other_metrics</th>\n",
       "      <th>metrics_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.694246</td>\n",
       "      <td>Graph Creation</td>\n",
       "      <td>debug_mode</td>\n",
       "      <td>Off</td>\n",
       "      <td>threshold</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0:00:02.158263</td>\n",
       "      <td>n_movies_model</td>\n",
       "      <td>5625</td>\n",
       "      <td>acc</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>Random Walk &amp; Prediction</td>\n",
       "      <td>n_movies_validation</td>\n",
       "      <td>1400</td>\n",
       "      <td>tpr</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0:03:20.514540</td>\n",
       "      <td>walk_steps</td>\n",
       "      <td>40</td>\n",
       "      <td>fpr</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>Threshold search</td>\n",
       "      <td>beta</td>\n",
       "      <td>0.15</td>\n",
       "      <td>tnr</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>0:00:00.005410</td>\n",
       "      <td>top_neighbor</td>\n",
       "      <td>20</td>\n",
       "      <td>fnr</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>TOTAL TIME</td>\n",
       "      <td>n_test_users</td>\n",
       "      <td>65</td>\n",
       "      <td>precision</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>0:03:22.678213</td>\n",
       "      <td>threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>f1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>start_index_v</td>\n",
       "      <td>5625</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>file_name</td>\n",
       "      <td>data/movies.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>top_N_suggestions</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AUC                 Calc_Time             lst_name        lst_value  \\\n",
       "0   0.694246  Graph Creation            debug_mode           Off               \n",
       "1             0:00:02.158263            n_movies_model       5625              \n",
       "2             Random Walk & Prediction  n_movies_validation  1400              \n",
       "3             0:03:20.514540            walk_steps           40                \n",
       "4             Threshold search          beta                 0.15              \n",
       "5             0:00:00.005410            top_neighbor         20                \n",
       "6             TOTAL TIME                n_test_users         65                \n",
       "7             0:03:22.678213            threshold            0                 \n",
       "8                                       start_index_v        5625              \n",
       "9                                       file_name            data/movies.txt   \n",
       "10                                      top_N_suggestions    1                 \n",
       "11                                                                             \n",
       "12                                                                             \n",
       "13                                                                             \n",
       "14                                                                             \n",
       "\n",
       "   other_metrics metrics_val  \n",
       "0   threshold     0           \n",
       "1   acc                       \n",
       "2   tpr                       \n",
       "3   fpr                       \n",
       "4   tnr                       \n",
       "5   fnr                       \n",
       "6   precision                 \n",
       "7   f1                        \n",
       "8                             \n",
       "9                             \n",
       "10                            \n",
       "11                            \n",
       "12                            \n",
       "13                            \n",
       "14                            "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_perf_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 1000\n",
    "df_FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeDataView([('B00004RNYG', 'A2F3SXHT6RBV81')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_connected_gr_amazon_movies_VAL.edges('B00004RNYG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'data/movies.txt'; n_movies = 1000; n_movies_v = 20500; n_test_users = 100; walk_steps = 40\n",
    "start_index_v = n_movies; beta = 0.1; top_neighbor = 50; top_N_movie_suggestions = 1\n",
    "\n",
    "#file_name = 'data/movies.txt'; n_movies = 2000; n_movies_v = 2000; n_test_users = 40; walk_steps = 30\n",
    "#start_index_v = n_movies; beta = 0.15; top_neighbor = 50\n",
    "\n",
    "#lst_n_movies_test = [20000, 30000, 40000, 50000]\n",
    "#lst_n_movies_test_v = [10000, 11000, 12000, 13000, 14000]\n",
    "#lst_n_movies_test_v = [2000, 4000, 6000, 8000]\n",
    "lst_n_movies_test_v = [1000]\n",
    "\n",
    "start_time_ALL = datetime.datetime.now()\n",
    "#for n_movies in lst_n_movies_test:\n",
    "for n_movies_v in lst_n_movies_test_v:\n",
    "    start_index_v = n_movies\n",
    "    start_time_part1 = datetime.datetime.now()\n",
    "\n",
    "    print('\\nn_movies = {} .. n_movies_v = {} .. n_test_users = {}'.format(n_movies, n_movies_v, n_test_users))\n",
    "    print('walk_steps = {} .. top_neighbor = {}'.format(walk_steps, top_neighbor))\n",
    "    print('----------------------------------------------')\n",
    "    print('Calculation starts for above values: {}'.format(start_time_part1))\n",
    "\n",
    "    max_connected_gr_amazon_movies, max_connected_gr_amazon_movies_VAL = \\\n",
    "    predict_amazon.create_graphs(file_name, n_movies, n_movies_v, start_index_v)\n",
    "\n",
    "    end_time_part1 = datetime.datetime.now()\n",
    "    total_time_part1 = end_time_part1 - start_time_part1\n",
    "    print('**********************************************')\n",
    "    print('Calculation time for ALL-Part-1: {}'.format(total_time_part1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpComp = comp.GraphComp()\n",
    "\n",
    "bottom_nodes, top_nodes = bipartite.sets(max_connected_gr_amazon_movies)\n",
    "bottom_nodes_v, top_nodes_v = bipartite.sets(max_connected_gr_amazon_movies_VAL)\n",
    "\n",
    "grpComp.movie_user_compare_datasets(top_nodes_v, top_nodes, bottom_nodes_v, bottom_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_users=8\n",
    "df_FINAL, df_FINAL_all = \\\n",
    "    predict_amazon.run_validation_TOP_N(max_connected_gr_amazon_movies, max_connected_gr_amazon_movies_VAL,\\\n",
    "                                  walk_steps, n_test_users, beta, top_neighbor, top_N_movie_suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_new = 'B003AI2VGA'\n",
    "predict_amazon.df_movie_similarity.query(\"movie_name=='\" + mv_new + \"'\").values[0].tolist()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_num = len(predict_amazon.df_movie_similarity)\n",
    "list(predict_amazon.df_movie_similarity.loc[row_num-1])[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_connected_gr_amazon_movies.edges('AQP1VPK16SVWM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_N_suggestions=2\n",
    "top_K_df_movie_similarity = predict_amazon.df_movie_similarity.tail(top_N_suggestions)\n",
    "lst_top_movie_suggestions = []\n",
    "for mv in top_K_df_movie_similarity.values:\n",
    "    lst_top_movie_suggestions.append(mv[1])\n",
    "    #print(mv)\n",
    "    \n",
    "print(lst_top_movie_suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_amazon.df_movie_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_amazon.df_summary_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_amazon.df_summary_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_amazon.R_sorted[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_R = predict_amazon.R_vector.tolist()[0]\n",
    "for idx in predict_amazon.R_sorted[0][0]:\n",
    "    print('idx={} .. node={} .. score={}'.format(idx, predict_amazon.node_list[idx], list_R[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FINAL_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_amazon.node_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(max_connected_gr_amazon_movies.edges(list(bottom_nodes)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(bottom_nodes)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_df = predict_amazon.show_parameters_in_use()\n",
    "params_df.style.set_properties(**{'text-align': 'left'})\n",
    "\n",
    "df_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is taking SOOOOOO LONG time\n",
    "#d_model = nx.diameter(max_connected_gr_amazon_movies)\n",
    "#d_test = nx.diameter(max_connected_gr_amazon_movies_VAL)\n",
    "#print('Diameter of MODEL: {}\\tTEST: {}'.format(d_model, d_test))\n",
    "\n",
    "# centrality is fast\n",
    "#centrality = nx.eigenvector_centrality_numpy(max_connected_gr_amazon_movies_VAL)\n",
    "#print(centrality)\n",
    "\n",
    "# if we use a small k, it doesn't take much time\n",
    "#bc = nx.betweenness_centrality(max_connected_gr_amazon_movies_VAL, k=100)\n",
    "#print(bc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(max_connected_gr_amazon_movies.edges('A1N0LCPR7O7OLL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as st\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "bottom_nodes, top_nodes = bipartite.sets(max_connected_gr_amazon_movies_VAL)\n",
    "# top_nodes=movies   ...  bottom_nodes=users\n",
    "degree_centrality = bipartite.degree_centrality(max_connected_gr_amazon_movies_VAL, top_nodes)\n",
    "#betweenness_centrality = bipartite.betweenness_centrality(max_connected_gr_amazon_movies_VAL, top_nodes)\n",
    "#closeness_centrality = bipartite.closeness_centrality(max_connected_gr_amazon_movies_VAL, top_nodes)\n",
    "#st.mean(list(degree_centrality.values()))\n",
    "st.mean(list(betweenness_centrality.values()))\n",
    "#---- degree_centrality (normalized) = deg(v)/max_possible_edges\n",
    "# bottom-nodes: avg normalized-degree_centrality: 0.003492891468893659=VAL  ....  0.001348452313463792\n",
    "# top-nodes: avg normalized-degree_centrality:    0.003492891468893659=VAL  ....  0.001348452313463792\n",
    "#---- closeness_centrality\n",
    "#---- https://networkx.github.io/documentation/stable/reference/algorithms/generated/networkx.algorithms.bipartite.centrality.closeness_centrality.html#networkx.algorithms.bipartite.centrality.closeness_centrality\n",
    "# bottom-nodes: avg. closeness_centrality: ?=VAL                   ....  ?\n",
    "# top-nodes: avg. closeness_centrality:    0.3937692751347393=VAL  ....  ?\n",
    "#---- betweenness_centrality\n",
    "# even if select bottom or top nodes, it always gives the result for bottom_nodes=USERS\n",
    "# bottom-nodes: avg. betweenness_centrality: 1.2469622543950363=VAL  (just gave the avg. degree..)  ....  ?\n",
    "# top-nodes: avg. betweenness_centrality:    1.2469622543950363=VAL  ....  ?\n",
    "#----\n",
    "# degree distribution\n",
    "#degrees(B, nodes[, weight])\n",
    "# careful here.. if you pass top_nodes as an argument, \n",
    "# it returns the values for bottom_nodes as the first result and the top_nodes as the second result.. and vice versa\n",
    "#degree_distribution_Bottom, degree_distribution_TOP = bipartite.degrees(max_connected_gr_amazon_movies_VAL, top_nodes)\n",
    "#print(len(degree_distribution_TOP))\n",
    "#----\n",
    "#bipartite.color(max_connected_gr_amazon_movies_VAL)\n",
    "#----\n",
    "# returns the same for both bottom and top... same value with avg normalized-degree_centrality\n",
    "#dens_m = bipartite.density(max_connected_gr_amazon_movies_VAL, bottom_nodes)\n",
    "#print(dens_m)\n",
    "#---- clustering coeff for the whole graph\n",
    "#avg_cluster = bipartite.average_clustering(max_connected_gr_amazon_movies_VAL, bottom_nodes)\n",
    "#print(avg_cluster)\n",
    "# 1.2469622543950363 >> (just gave the avg. degree..)\n",
    "#----\n",
    "#n_redundancy = bipartite.node_redundancy(max_connected_gr_amazon_movies_VAL, bottom_nodes)\n",
    "#print(n_redundancy)\n",
    "# NetworkXError: Cannot compute redundancy coefficient for a node that has fewer than two neighbors.\n",
    "print('{} .. {}'.format(len(top_nodes), len(bottom_nodes)))\n",
    "357*0.003492891468893659\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_amazon.df_summary_ratio_v.query(\"movie=='B000N2HD7I'\").values[0].tolist()[1]\n",
    "pd.options.display.max_rows = 1000\n",
    "predict_amazon.df_summary_ratio_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes too much time to run, as well\n",
    "# The eccentricity of a node v is the maximum distance from v to all other nodes in G.\n",
    "# Returns: ecc â€“ A dictionary of eccentricity values keyed by node.\n",
    "# eccentricity(G, v=None, sp=None)\n",
    "#e_model = nx.eccentricity(max_connected_gr_amazon_movies)\n",
    "#e_test = nx.eccentricity(max_connected_gr_amazon_movies_VAL)\n",
    "\n",
    "#print('Eccentricity of MODEL: {}\\tTEST: {}'.format(e_model, e_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below table shows the prediction for threshold>10% so don't pay attention to it\n",
    "# also tot_rev_m_NEW & OLD will be double checked, seems like a bug\n",
    "pd.options.display.max_rows = 1000\n",
    "df_FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.options.display.max_rows = 35500\n",
    "df_FINAL_all.query(\"user=='A22GKUN35R09KN' and movie=='B000J6I0TS'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "total_reviews = 0\n",
    "        # total number of reviews that those 100 test users did in dataset-2\n",
    "        for u in df_FINAL['user'].unique():\n",
    "            n_movie_reviewed_new = df_FINAL.query(\"user == '\" + u + \"'\")['n_new_edge'][0]\n",
    "            total_reviews += n_movie_reviewed_new\n",
    "\n",
    "\n",
    "\n",
    "for u in df_FINAL['user'].unique():\n",
    "    print(u)\n",
    "    print(df_FINAL.query(\"user == '\" + u + \"'\")['n_new_edge'].values[0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_FINAL['movie'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for t in thresholds:\n",
    "    acc, tpr, fpr, tnr, fnr, ppv, f1 = predict_amazon.final_summary_threshold_based(df_FINAL, t)\n",
    "    lst_t = [t,  acc, tpr, fpr, tnr, fnr, ppv, f1]\n",
    "    lst_presicion_based.append(lst_t)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df_FINAL_copy = df_FINAL.copy()\n",
    "\n",
    "threshold = 4\n",
    "for i in range(len(df_FINAL_copy)):\n",
    "    if df_FINAL_copy.loc[i, 'ngbr_ratio'] > threshold:\n",
    "        df_FINAL_copy.loc[i, 'prediction'] = 1\n",
    "    else:\n",
    "        df_FINAL_copy.loc[i, 'prediction'] = 0\n",
    "        \n",
    "acc, tpr, fpr, tnr, ppv, f1 = predict_amazon.final_summary(df_FINAL_copy)\n",
    "\n",
    "print(tpr)\n",
    "\n",
    "#p_recall = tpr / (tpr + fnr)\n",
    "#print(recall)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_true_val = df_FINAL.loc[:, 'reality'].values.tolist()\n",
    "lst_ratio_val = df_FINAL.loc[:, 'ngbr_ratio'].values.tolist()\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(lst_true_val, lst_ratio_val)  #, pos_label=2\n",
    "lst_tpr = list(tpr); lst_fpr = list(fpr); lst_thresholds = list(thresholds) \n",
    "\n",
    "print(tpr)\n",
    "print(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "y_true = df_FINAL.loc[:, 'reality'].values.tolist()\n",
    "y_pred = df_FINAL.loc[:, 'ngbr_ratio'].values.tolist()\n",
    "\n",
    "roc_auc = roc_auc_score(y_true, y_pred)\n",
    "print(roc_auc)\n",
    "\n",
    "#precision = precision_score(y_true, y_pred, average='macro') # 'micro'  'weighted' None  average=None, zero_division=1\n",
    "#print(precision)\n",
    "\n",
    "precision_recall = precision_recall_curve(y_true, y_pred)\n",
    "#print(list(precision_recall))\n",
    "\n",
    "avg_precision = average_precision_score(y_true, y_pred)\n",
    "#print(avg_precision)\n",
    "\n",
    "#lst_tpr = \n",
    "\n",
    "#for i in range(len(lst_tpr)):\n",
    " #   lst_precision[i] = lst_tpr[i]/(lst_tpr[i] + lst_fpr[i])\n",
    "    \n",
    "#print(lst_precision)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df_FINAL_copy = df_FINAL.copy()\n",
    "\n",
    "threshold = 4\n",
    "for i in range(len(df_FINAL_copy)):\n",
    "    if df_FINAL_copy.loc[i, 'ngbr_ratio'] >= threshold:\n",
    "        df_FINAL_copy.loc[i, 'prediction'] = 1\n",
    "    else:\n",
    "        df_FINAL_copy.loc[i, 'prediction'] = 0\n",
    "\n",
    "tp = len(df_FINAL_copy.query(\"prediction==1 and reality==1\").values)\n",
    "fp = len(df_FINAL_copy.query(\"prediction==1 and reality==0\").values)\n",
    "tn = len(df_FINAL_copy.query(\"prediction==0 and reality==0\").values)\n",
    "fn = len(df_FINAL_copy.query(\"prediction==0 and reality==1\").values)\n",
    "\n",
    "p_precise = tp / (tp + fp)\n",
    "p_recall = tp / (tp + fn)\n",
    "\n",
    "print(p_precise)\n",
    "print(p_recall)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#u1=df_FINAL_copy.query(\"(prediction>0 or reality>0) and n_new_edge>0\")\n",
    "#u1=df_FINAL_copy.query(\"user=='AR15V2ULA2EYM' and (prediction>0 or reality>0) and n_new_edge>0 \").sort_values(by='ngbr_ratio', ascending=False)\n",
    "#u1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTES\n",
    "'''\n",
    "Model1: \n",
    "n_movies = 40000 .. n_movies_v = 12000 .. n_test_users = 100 walk_steps = 40 .. top_neighbor = 50 >> AUC = 80.23\n",
    "Model2: \n",
    "n_movies = 40000 .. n_movies_v = 12000 .. n_test_users = 100 walk_steps = 40 .. top_neighbor = 50 >> AUC = 86.89 .. 71.15 .. \n",
    "Model3: \n",
    "n_movies = 40000 .. n_movies_v = 12000 .. n_test_users = 100 walk_steps = 40 .. top_neighbor = 50 >> AUC = \n",
    "Model4: \n",
    "n_movies = 40000 .. n_movies_v = 12000 .. n_test_users = 100 walk_steps = 40 .. top_neighbor = 50 >> AUC = \n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Amazon_movies.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
